#!/bin/bash

# Create the Docker image for the service.
# Label it with the first 7 chars of GIT_COMMIT and also with :latest
# All actions are local to the VM; does not use aws or ecs-cli.
# Should be run before deploy-to-ecs is run.
# Assumes the environemnt variable GIT_COMMIT is set (typically by Jenkins).
# Assumes the directory for the service exists in this directory,
# its name matches "*-ecs", and it is the only directory that matches.

# Fail on any error; unset variables are errors; show commands before executing:
set -eux
PROJECT="$1"
ENV="$2"
aws_region="$3"

GIT_COMMIT=${GIT_COMMIT:-unknown}
GIT_COMMIT=${GIT_COMMIT:0:7}

ECS_DIR=$(find . -maxdepth 1 -type d -name "*-ecs")

# TODO: see if logging anything from this script would be helpful

# TODO: make sure we're in the correct (root) directory
# Can just check for Dockerfile, and cd .. if not there

date

echo "Running in $PWD"
echo "Project = $PROJECT"
echo "Target Environment = $ENV"

docker --version
ls -al Docker* generate-keystore

password=$(echo -n "fpnggretbevrf" | tr '[a-mn-zA-MN-Z]' '[n-za-mN-ZA-M]')
# TODO: figure out how secure the keystore password needs to be, and how to get it

echo "Generating the keystore and .env file..."
cat <<EOF > gk-input
keystore
$password
Nobody
DevOps
Excella
Arlington
VA
US
yes
EOF

./generate-keystore < gk-input && rm gk-input

cp -p .env $ECS_DIR/

# Add DB values to .env :
DB_USER=$(aws ssm get-parameter --region $aws_region --name "/$PROJECT/$ENV/rds/username" --with-decryption --query "Parameter.Value" --out text)
DB_PASSWORD=$(aws ssm get-parameter --region $aws_region --name "/$PROJECT/$ENV/rds/password" --with-decryption --query "Parameter.Value" --out text)
DB_ENDPOINT=$(aws ssm get-parameter --region $aws_region --name "/$PROJECT/$ENV/rds/endpoint" --query "Parameter.Value" --out text)

# Split at : into HOST and PORT:
read DB_HOST DB_PORT <<<$(IFS=":"; echo $DB_ENDPOINT)

# Note: do NOT use double-quotes around the values; bash isn't interpreting .env: ecs-cli compose is, and it does not drop quotes.
cat >> $ECS_DIR/.env <<EOF
DB_HOST=${DB_HOST}
DB_PORT=${DB_PORT}
DB_USER=${DB_USER}
DB_PASSWORD=${DB_PASSWORD}
AWS_REGION=${aws_region}
EOF

# Get the name ("repository" in Docker lingo) of the image from the doacker-compose.yml file:
grep "image: .*amazonaws.com/" $ECS_DIR/docker-compose.yml
IMAGE_REPO=$(grep "image: .*amazonaws.com/" $ECS_DIR/docker-compose.yml | sed "s/^[^\/]*\///")
echo "Image repository from $ECS_DIR/docker-compose.yml is $IMAGE_REPO"
if [[ "$IMAGE_REPO" = "" ]] ; then
    echo "ERROR: missing or empty image repository in $ECS_DIR/docker-compose.yml .  Quitting...."
    exit 2;
fi

echo "git commit hash is $GIT_COMMIT"
mkdir -p src/assets/img
git log -1 > src/main/resources/commit

echo "Building the $IMAGE_REPO Docker image..."
# TODO: may need sudo, or to run this script as sudo?
docker build -t $IMAGE_REPO:$GIT_COMMIT . -f $ECS_DIR/Dockerfile
# deploy script will look for $IMAGE_REPO:$GIT_COMMIT *and* $IMAGE_REPO:latest
# TODO: should we even be tagging it "latest" yet?
docker tag $IMAGE_REPO:$GIT_COMMIT $IMAGE_REPO:latest

echo "Checking for the Docker image..."
docker image ls | grep $IMAGE_REPO

date
